#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ GPU –∏ CUDA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è XTTS v2
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
"""

import sys
import platform
import subprocess
import os

def print_header():
    """–í—ã–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    print("=" * 60)
    print("üîç –ü–†–û–í–ï–†–ö–ê –ü–û–î–î–ï–†–ñ–ö–ò GPU –î–õ–Ø XTTS v2")
    print("=" * 60)
    print()

def check_system_info():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ"""
    print("üìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –°–ò–°–¢–ï–ú–ï:")
    print(f"‚Ä¢ –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞: {platform.system()} {platform.release()}")
    print(f"‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {platform.machine()}")
    print(f"‚Ä¢ Python –≤–µ—Ä—Å–∏—è: {sys.version.split()[0]}")
    print()

def check_nvidia_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è NVIDIA GPU"""
    print("üéÆ –ü–†–û–í–ï–†–ö–ê NVIDIA GPU:")
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ nvidia-ml-py
        import pynvml
        pynvml.nvmlInit()
        
        device_count = pynvml.nvmlDeviceGetCount()
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ NVIDIA GPU: {device_count} —É—Å—Ç—Ä–æ–π—Å—Ç–≤")
        
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            name = pynvml.nvmlDeviceGetName(handle)
            memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
            
            print(f"  üì∫ GPU {i}: {name.decode('utf-8')}")
            print(f"    üíæ –ü–∞–º—è—Ç—å: {memory.total // 1024**3} –ì–ë")
            print(f"    üî• –°–≤–æ–±–æ–¥–Ω–æ: {memory.free // 1024**3} –ì–ë")
            
        return True
        
    except ImportError:
        print("‚ùå nvidia-ml-py –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install nvidia-ml-py")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ NVIDIA GPU: {e}")
        return False

def check_cuda_installation():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ CUDA"""
    print("üîß –ü–†–û–í–ï–†–ö–ê CUDA:")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    cuda_path = None
    for var in ['CUDA_PATH', 'CUDA_HOME']:
        if var in os.environ:
            cuda_path = os.environ[var]
            print(f"‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è {var}: {cuda_path}")
    
    if not cuda_path:
        print("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ nvidia-smi
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ nvidia-smi —Ä–∞–±–æ—Ç–∞–µ—Ç")
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é CUDA –∏–∑ –≤—ã–≤–æ–¥–∞
            for line in result.stdout.split('\n'):
                if 'CUDA Version' in line:
                    cuda_version = line.split('CUDA Version:')[1].strip()
                    print(f"üìä –í–µ—Ä—Å–∏—è CUDA: {cuda_version}")
                    break
        else:
            print("‚ùå nvidia-smi –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    except FileNotFoundError:
        print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ nvidia-smi: {e}")
    
    print()

def check_pytorch_cuda():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA –≤ PyTorch"""
    print("üî• –ü–†–û–í–ï–†–ö–ê PYTORCH + CUDA:")
    
    try:
        import torch
        
        print(f"‚úÖ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
        print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
            print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory
                print(f"  üì∫ GPU {i}: {gpu_name}")
                print(f"    üíæ –ü–∞–º—è—Ç—å: {gpu_memory // 1024**3} –ì–ë")
            
            # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            print("\nüß™ –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
            device = torch.device('cuda:0')
            x = torch.randn(1000, 1000).to(device)
            y = torch.randn(1000, 1000).to(device)
            
            import time
            start_time = time.time()
            z = torch.mm(x, y)
            torch.cuda.synchronize()
            end_time = time.time()
            
            print(f"‚úÖ GPU —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω –∑–∞ {end_time - start_time:.3f} —Å–µ–∫")
            
        else:
            print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ PyTorch")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA:")
            print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        
    except ImportError:
        print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install torch")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ PyTorch: {e}")
    
    print()

def check_other_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ GPU"""
    print("üîç –ü–†–û–í–ï–†–ö–ê –î–†–£–ì–ò–• GPU:")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ AMD ROCm
    try:
        import torch
        if hasattr(torch, 'hip') and torch.hip.is_available():
            print("‚úÖ AMD ROCm –¥–æ—Å—Ç—É–ø–Ω–∞")
        else:
            print("‚ùå AMD ROCm –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
    except:
        print("‚ùå AMD ROCm –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Apple Metal
    try:
        import torch
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            print("‚úÖ Apple Metal –¥–æ—Å—Ç—É–ø–Ω–∞")
        else:
            print("‚ùå Apple Metal –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
    except:
        print("‚ùå Apple Metal –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
    
    print()

def check_xtts_gpu_compatibility():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ XTTS v2 —Å GPU"""
    print("üé§ –ü–†–û–í–ï–†–ö–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò XTTS v2:")
    
    try:
        from TTS.api import TTS
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        models = TTS.list_models()
        xtts_models = [m for m in models if 'xtts' in m.lower()]
        
        if xtts_models:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ XTTS –º–æ–¥–µ–ª–µ–π: {len(xtts_models)}")
            for model in xtts_models[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"  üì¶ {model}")
        else:
            print("‚ùå XTTS –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É GPU –≤ TTS
        print("\nüîß –ü–û–î–î–ï–†–ñ–ö–ê GPU –í TTS:")
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å —Å GPU
            import torch
            if torch.cuda.is_available():
                print("‚úÖ TTS –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GPU")
                print("üí° XTTS v2 –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU")
            else:
                print("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, TTS –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU –≤ TTS: {e}")
        
    except ImportError:
        print("‚ùå TTS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install TTS")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ TTS: {e}")
    
    print()

def provide_recommendations():
    """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    
    try:
        import torch
        if torch.cuda.is_available():
            print("‚úÖ –í–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è GPU-—É—Å–∫–æ—Ä–µ–Ω–∏—è!")
            print("üöÄ XTTS v2 –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ")
            print("üìä –û–∂–∏–¥–∞–µ–º–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: 3-10x")
        else:
            print("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –Ω–æ —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ")
            print("üíª XTTS v2 –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU")
            print("üìä –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: 10-30 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç")
            
            print("\nüîß –î–õ–Ø –í–ö–õ–Æ–ß–ï–ù–ò–Ø GPU:")
            print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA")
            print("2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit")
            print("3. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA:")
            print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    
    except ImportError:
        print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ GPU")
    
    print()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import os
    
    print_header()
    check_system_info()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã GPU
    nvidia_available = check_nvidia_gpu()
    check_cuda_installation()
    check_pytorch_cuda()
    check_other_gpu()
    check_xtts_gpu_compatibility()
    provide_recommendations()
    
    print("=" * 60)
    print("‚úÖ –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 60)

if __name__ == "__main__":
    main()
